{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of the data samples \n",
      "   Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina... \n",
      "\n",
      "Dimension of the data set:\n",
      " (5572, 2) \n",
      "\n",
      "Distribution of the data set:\n",
      " Label\n",
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: proportion, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sms_spam_data_set = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "print(\"Examples of the data samples \\n\", sms_spam_data_set.head(3), \"\\n\")\n",
    "print(\"Dimension of the data set:\\n\", sms_spam_data_set.shape, \"\\n\")\n",
    "print(\"Distribution of the data set:\\n\", sms_spam_data_set['Label'].value_counts(normalize=True), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribtuion of the training data set:\n",
      " Label\n",
      "ham     0.866726\n",
      "spam    0.133274\n",
      "Name: proportion, dtype: float64 4457 \n",
      "\n",
      "Distribtuion of the testing data set:\n",
      " Label\n",
      "ham     0.86278\n",
      "spam    0.13722\n",
      "Name: proportion, dtype: float64 1115 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perform train/test split\n",
    "sms_texts, labels = sms_spam_data_set.SMS, sms_spam_data_set.Label\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "sms_texts_train, sms_texts_test, labels_train, labels_test = train_test_split(sms_texts, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "sms_texts_train = sms_texts_train.reset_index(drop=True)\n",
    "labels_train = labels_train.reset_index(drop=True)\n",
    "\n",
    "sms_texts_test = sms_texts_test.reset_index(drop=True)\n",
    "labels_test = labels_test.reset_index(drop=True)\n",
    "\n",
    "print(\"Distribtuion of the training data set:\\n\", labels_train.value_counts(normalize=True),  labels_train.shape[0], \"\\n\")\n",
    "\n",
    "print(\"Distribtuion of the testing data set:\\n\", labels_test.value_counts(normalize=True), labels_test.shape[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (the number of all possible words in the trainning data):\n",
      " 11789 \n",
      "\n",
      "Examples of the training data \n",
      "   Label                                                SMS  recd.  science...  \\\n",
      "0  spam  Double mins and txts 4 6months FREE Bluetooth ...      0           0   \n",
      "1   ham  Did you get any gift? This year i didnt get an...      0           0   \n",
      "2   ham  Ever green quote ever told by Jerry in cartoon...      0           0   \n",
      "\n",
      "   accident  roast  special,  5wkg  jenxxx.  cbe.  ...  tomorro  \\\n",
      "0         0      0         0     0        0     0  ...        0   \n",
      "1         0      0         0     0        0     0  ...        0   \n",
      "2         0      0         0     0        0     0  ...        0   \n",
      "\n",
      "   www.txttowin.co.uk  else  ip4.  map  valid12hrs  official  them..:-p  4few  \\\n",
      "0                   0     0     0    0           0         0          0     0   \n",
      "1                   0     0     0    0           0         0          0     0   \n",
      "2                   0     0     0    0           0         0          0     0   \n",
      "\n",
      "   yuo  \n",
      "0    0  \n",
      "1    0  \n",
      "2    0  \n",
      "\n",
      "[3 rows x 11791 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Function to convert input sms texts to feature vectors using BoW representation\n",
    "def smsTextsToVectors(sms_texts):\n",
    "    sms_texts = sms_texts.str.replace('\\W', ' ') #Remove punctuation\n",
    "    sms_texts = sms_texts.str.lower()\n",
    "    sms_texts = sms_texts.str.split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for sms in sms_texts:\n",
    "        for word in sms:\n",
    "            vocabulary.append(word)\n",
    "        \n",
    "    vocabulary = list(set(vocabulary))\n",
    "    \n",
    "    word_counts_per_sms = {unique_word: [0] * len(sms_texts) for unique_word in vocabulary}\n",
    "    \n",
    "    for index, sms in enumerate(sms_texts):\n",
    "        for word in sms:\n",
    "            word_counts_per_sms[word][index] += 1\n",
    "            \n",
    "    return word_counts_per_sms, vocabulary\n",
    "\n",
    "word_counts_per_sms, vocabulary  = smsTextsToVectors(sms_texts_train) \n",
    "x_train = pd.DataFrame(word_counts_per_sms)\n",
    "print(\"Features (the number of all possible words in the trainning data):\\n\", len(vocabulary), \"\\n\")\n",
    "\n",
    "training_data_set = pd.concat([labels_train, sms_texts_train, x_train], axis=1)\n",
    "print(\"Examples of the training data \\n\", training_data_set.head(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our estimate of P(y=spam) is  0.13327350235584473\n",
      "Our estimate of P(y=ham) is  0.8667264976441552\n"
     ]
    }
   ],
   "source": [
    "x_train_spam = x_train[labels_train == 'spam']\n",
    "x_train_ham = x_train[labels_train == 'ham']\n",
    "\n",
    "#Estimate P(y=spam) and P(y=ham)\n",
    "p_spam = len(x_train_spam)/len(x_train)\n",
    "print(\"Our estimate of P(y=spam) is \", p_spam)\n",
    "\n",
    "p_ham = len(x_train_ham)/len(x_train)\n",
    "print(\"Our estimate of P(y=ham) is \", p_ham)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate parameters\n",
    "theta_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "theta_ham =  {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "#Estimate the probability distribution of selecting each word\n",
    "# uncomment to implement the following\n",
    "#for word in vocabulary:\n",
    "    # uncomment to implement the following\n",
    "    # theta_spam[word] = ?\n",
    "    \n",
    "    # uncomment to implement the following\n",
    "    #theta_ham[word] = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implment Naive Bayes classifier\n",
    "import re, math\n",
    "def textToVector(message):\n",
    "    message = re.sub('\\W', ' ', message) #Remove punctuation\n",
    "    message = message.lower().split()\n",
    "\n",
    "    vocabulary = []\n",
    "    for word in  message:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "    vocabulary = list(set(vocabulary))\n",
    "    \n",
    "    word_counts = {unique_word: 0 for unique_word in vocabulary}\n",
    "    \n",
    "    for word in message:\n",
    "            word_counts[word] += 1\n",
    "            \n",
    "    return word_counts, vocabulary\n",
    "\n",
    "def naive_bayes_classify(sms_text):\n",
    "    x_test, vocabulary_test = textToVector(sms_text)\n",
    "    \n",
    "    # uncomment to implement the following\n",
    "    # p_spam_given_sms = ?\n",
    "    # p_ham_given_sms = ?\n",
    "\n",
    "    print('Estimate of log(P(SPAM|message=',  sms_text, ')) =', log_p_spam_given_sms)\n",
    "    print('Estimate of log(P(HAM|message=',  sms_text, ')) =', log_p_ham_given_sms)\n",
    "    isSpam = True\n",
    "    if(log_p_spam_given_sms > log_p_ham_given_sms):\n",
    "        isSpam = True\n",
    "    else:\n",
    "        isSpam = False\n",
    "    return isSpam\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_spam_given_sms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(naive_bayes_classify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWINNER!! This is the secret code to unlock the money: C3421.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(naive_bayes_classify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSounds good, Tom, then u there\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[1;32mIn[7], line 27\u001b[0m, in \u001b[0;36mnaive_bayes_classify\u001b[1;34m(sms_text)\u001b[0m\n\u001b[0;32m     21\u001b[0m x_test, vocabulary_test \u001b[38;5;241m=\u001b[39m textToVector(sms_text)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# uncomment to implement the following\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# p_spam_given_sms = ?\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# p_ham_given_sms = ?\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimate of log(P(SPAM|message=\u001b[39m\u001b[38;5;124m'\u001b[39m,  sms_text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)) =\u001b[39m\u001b[38;5;124m'\u001b[39m, p_spam_given_sms)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimate of log(P(HAM|message=\u001b[39m\u001b[38;5;124m'\u001b[39m,  sms_text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)) =\u001b[39m\u001b[38;5;124m'\u001b[39m, p_ham_given_sms)\n\u001b[0;32m     29\u001b[0m isSpam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'p_spam_given_sms' is not defined"
     ]
    }
   ],
   "source": [
    "print(naive_bayes_classify(\"WINNER!! This is the secret code to unlock the money: C3421.\"))\n",
    "print(naive_bayes_classify(\"Sounds good, Tom, then u there\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(sms_texts, labels):\n",
    "    mistakes = 0\n",
    "    for i, message in enumerate(sms_texts):\n",
    "        isSpam = naive_bayes_classify(message)\n",
    "        if isSpam and labels[i] != \"spam\":\n",
    "            mistakes += 1\n",
    "        elif not isSpam and labels[i] == \"spam\":\n",
    "            mistakes += 1\n",
    "    return (len(sms_texts)-mistakes)/len(sms_texts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate loss on training data\n",
    "print(\"Training accuracy:\", score(sms_texts_train, labels_train))\n",
    "#Calculate generalization loss\n",
    "print(\"Generalization accuracy:\", score(sms_texts_test, labels_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
