{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6610402230 ศิริสุข ทานธรรม"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets as ds\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed_value = 0\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "iris = ds.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Y[Y > 0] = 1\n",
    "Y[Y <= 0] = -1\n",
    "d = np.shape(X)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    class LinearClassifier:\n",
    "        def __init__(self, d):\n",
    "            self.dimension = d\n",
    "            self.bias = np.random.rand()\n",
    "            self.hyperplain_weight = None\n",
    "        \n",
    "        def fit(self, x_train: np.ndarray, y_train : np.ndarray):\n",
    "            weight = np.zeros(self.dimension) # init weight vector\n",
    "            weight = np.append(weight,self.bias)  # append bias to weight vector\n",
    "            while True:\n",
    "                miss = 0 # count miss classify \n",
    "                for i,data in enumerate(x_train):\n",
    "                    y_hat = np.dot(weight,np.append(data,1))\n",
    "                    if(y_hat * y_train[i] < 0): #(wTxi)yi become < 0 if wTxi not same sign as yi\n",
    "                        miss += 1\n",
    "                        weight = weight + (np.append(data,0) * y_train[i]) # adjust the hyperplain\n",
    "                if (miss == 0):\n",
    "                    self.hyperplain_weight = weight\n",
    "                    break\n",
    "            \n",
    "        def predict(self, x_test : np.ndarray):\n",
    "            weight : np.ndarray = self.hyperplain_weight\n",
    "            predicts = np.array([])\n",
    "            for data in x_test:\n",
    "                y_hat = np.dot(weight,np.append(data,1))\n",
    "                y_hat = (1 if y_hat >= 0 else -1)\n",
    "                predicts = np.append(predicts, y_hat)\n",
    "            return predicts\n",
    "                \n",
    "        def score(self, x_test : np.ndarray, y_test : np.ndarray):\n",
    "            predictions = self.predict(x_test)\n",
    "            # print(x_test.shape,y_test.shape,predictions)\n",
    "            loss = np.sum(predictions != y_test) / x_test.size\n",
    "            return 1 - loss\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "h = Perceptron.LinearClassifier(d)\n",
    "h.fit(x_train, y_train)\n",
    "h.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize\n",
    "In this experiment of constucting the perceptron linear classifier for the iris dataset\n",
    "our X (feature space) is 4-dimensional vector related to iris flower. And the label space is in the set of {-1,1}, the binary classification. At the first step, I configured the random seed to our experiement then define the perceptron class.\n",
    "1. initialize the perceptron model\n",
    "   - setup the dimension for weight vector \n",
    "   - setup bias for the hyperplain\n",
    "2. training with linear classifier algorithm\n",
    "   - define the weight vector (zero vector) that define the hyperplain\n",
    "   - for easier I've bring the bias into the weight vector\n",
    "   - try to loop through data until the hyperplain fit to our data (miss classify = 0)\n",
    "     - define the y_hat as the weight vector dot with data(append 1 to calculate with bias)\n",
    "     - if y_hat * y_real and not the same, the output becomes < zero (miss classify)\n",
    "     - for the miss classify case, adjust the weight vector with adding current weight vector to the inverse of data vector to make the hyperplain more accurate splitting our data (append 0 with data vector to keep the same bias)\n",
    "3. prediction\n",
    "   - make prediction with data by dot weight vector that define the hyperplain with data vector (appended bias) \n",
    "   - the answer the sign of dot product\n",
    "4. evaluate with zero/one loss metric\n",
    "   - the accuracy is 1 - loss(x_test,y_test)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
